{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "#IF THE INCEPTION IS TAKING TOO LONG.. TRY\n",
    "#from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Dense,GlobalAveragePooling2D, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2693 images belonging to 22 classes.\n",
      "Found 2190 images belonging to 22 classes.\n",
      "Found 2220 images belonging to 22 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "input_shape = 224\n",
    "\n",
    "#YOU CAN REDUCE THE BATCH IF IT'S TAKING TOO LONG\n",
    "train_gen = datagen.flow_from_directory('foodV2/train/', target_size=(input_shape,input_shape), batch_size=32,class_mode='categorical',shuffle=True, color_mode='rgb')\n",
    "val_gen = datagen.flow_from_directory('foodV2/val/', target_size=(input_shape,input_shape), batch_size=32, class_mode='categorical',shuffle=True, color_mode='rgb')\n",
    "test_gen = datagen.flow_from_directory('foodV2/test/', target_size=(input_shape,input_shape), batch_size=32, class_mode='categorical',shuffle=True, color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foodModel(input_sh):\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(input_shape,input_shape,3), classes=1000)\n",
    "    #USE VGG IF IT'S TAKING TOO LONG\n",
    "    #base_model = VGG16(include_top=False, weights='imagenet', input_shape=(input_shape,input_shape,3), classes=1000)\n",
    "    for layer in base_model.layers:\n",
    "        #YOU CAN DECIDE IF YOU ARE GOING TO RETRAIN THE PRETRAINED MODEL, OR LEAVE IT AS IT IS WITH IT'S CURRENT WEIGHTS\n",
    "        layer.trainable = False\n",
    "    \n",
    "    #YOU CAN REDUCE THE NUMBER OF DENSE LAYERS IF IT'S TAKING TOO LONG\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    predictions = Dense(22, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input,outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 691 ms, total: 13.2 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "foodModel = foodModel(input_shape)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "foodModel.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/84 [===========>..................] - ETA: 8:06 - loss: 9.9437 - accuracy: 0.0650 "
     ]
    }
   ],
   "source": [
    "step_size_train = train_gen.n//train_gen.batch_size\n",
    "#REDUCE THE EPOCHS IF YOU WANT\n",
    "foodModel.fit_generator(generator=train_gen,steps_per_epoch=step_size_train,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foodModel.save('nakedFoodModel.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS WHERE WE GET FUCKED! GOOD LUCK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weighted_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ca1ff9964d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"foodModelV1.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/Environments/py35_env/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_custom_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m       weighted_metrics = convert_custom_objects(\n\u001b[0;32m--> 251\u001b[0;31m           training_config['weighted_metrics'])\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0msample_weight_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight_mode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0mloss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'weighted_metrics'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "new_model= tf.keras.models.load_model(filepath=\"foodModelV1.h5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(new_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "open(\"model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
